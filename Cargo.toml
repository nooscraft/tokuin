[package]
name = "tokuin"
version = "0.1.0"
edition = "2021"
authors = ["Tokuin Contributors"]
license = "MIT OR Apache-2.0"
description = "A fast CLI tool to estimate token usage and API costs for LLM prompts"
repository = "https://github.com/nooscraft/tokuin"
keywords = ["llm", "tokens", "openai", "claude", "cli", "prompt", "tokuin"]
categories = ["command-line-utilities", "development-tools"]

[dependencies]
# CLI
clap = { version = "4.5", features = ["derive"] }

# Error handling
thiserror = "1.0"

# OpenAI tokenization
tiktoken-rs = { version = "0.6", optional = true }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Configuration
toml = "0.8"

# Async runtime (optional for future features)
tokio = { version = "1.0", features = ["full"], optional = true }

# File watching
notify = { version = "5.0", optional = true }

# Markdown parsing
pulldown-cmark = { version = "0.9", optional = true }

# SentencePiece for Gemini and other models (optional, requires CMake)
# Note: Gemini works without this using approximation, but for exact counts install CMake:
#   macOS: brew install cmake
#   Linux: apt-get install cmake (or yum install cmake)
#   Windows: Download from https://cmake.org/download/
sentencepiece = { version = "0.12", optional = true }

# HTTP client for load testing
reqwest = { version = "0.12", default-features = false, features = ["json", "stream", "rustls-tls"], optional = true }
async-trait = { version = "0.1", optional = true }

# Progress bars for load testing
indicatif = { version = "0.17", optional = true }

# Latency histograms for metrics
hdrhistogram = { version = "7.5", optional = true }

# YAML parsing for prompt files
serde_yaml = { version = "0.9", optional = true }

# Random number generation for think time
fastrand = { version = "2.0", optional = true }

[features]
default = ["openai"]
openai = ["tiktoken-rs"]
watch = ["notify", "tokio"]
markdown = ["pulldown-cmark"]
gemini = []  # Gemini works without sentencepiece (uses approximation)
# For exact Gemini tokenization, enable sentencepiece: gemini-sentencepiece = ["sentencepiece"]
gemini-sentencepiece = ["sentencepiece"]
load-test = ["tokio", "reqwest", "async-trait", "indicatif", "hdrhistogram", "serde_yaml", "fastrand"]
all = ["openai", "watch", "markdown", "gemini", "load-test"]

[dev-dependencies]
# Testing
tempfile = "3.8"
httpmock = "0.7"

[[bin]]
name = "tokuin"
path = "src/main.rs"
